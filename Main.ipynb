{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import GlobalMaxPool2D\n",
    "from tensorflow.python.keras.layers import LSTM\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.python.keras.layers import Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.utils import np_utils, generic_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model: (None, 16, 64, 96, 32)\n",
      "(None, 16, 32, 48, 32)\n",
      "(None, 16, 32, 48, 64)\n",
      "(None, 16, 16, 24, 64)\n",
      "(None, 16, 16, 24, 128)\n",
      "(None, 16, 8, 12, 128)\n",
      "(None, 16, 8, 12, 256)\n",
      "(None, 16, 8, 12, 256)\n",
      "(None, 16, 8, 12, 256)\n",
      "(None, 16, 1, 1, 256)\n",
      "(None, 16, 256)\n",
      "(None, 16, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 83)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Building model: ', end=\"\")\n",
    "model = Sequential()\n",
    "#`channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n",
    "strides = (1,1,1)\n",
    "kernel_size = (3, 3, 3)\n",
    "model.add(Conv3D(32, kernel_size, strides=strides, activation='relu', padding='same', input_shape=(16, 64, 96, 3)))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv3D(64, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv3D(128, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(256, kernel_size, strides=strides, activation='relu',padding='same'))\n",
    "print(model.output_shape)\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(1,8,12)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Reshape((16, 256)))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(256))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [' Scroll_hand_towards_right',\n",
    " 'Scroll_hand_towards_left',\n",
    " 'Scroll_hand_downward',\n",
    " 'Scroll_hand_upward',\n",
    "'Scroll_hand_forward',\n",
    " 'Scroll_hand_backward',\n",
    " 'Cross_index_fingers',\n",
    " 'Zoom_in_with_fists',\n",
    " 'Zoom_out_with_fists',\n",
    " 'Rotate_fists_clockwise',\n",
    " 'Rotate_fists_counterclockwise',\n",
    " 'Zoom_in_with_fingers',\n",
    " 'Zoom_out_with_fingers',\n",
    " 'Rotate_fingers_clockwise',\n",
    " 'Rotate_fingers_counterclockwise',\n",
    " 'Click_with_index_finger',\n",
    " 'Sweep_diagonal',\n",
    " 'Sweep_circle',\n",
    " 'Sweep_cross',\n",
    " 'Sweep_checkmark',\n",
    " 'Static_fist',\n",
    " 'Measure(distance)',\n",
    " 'Photo_frame',\n",
    " 'Number_0',\n",
    " 'Number_1',\n",
    " 'Number_2',\n",
    " 'Number_3',\n",
    " 'Number_4',\n",
    " 'Number_5',\n",
    " 'Number_6',\n",
    " 'Number_7',\n",
    " 'Number_8',\n",
    " 'Number_9',\n",
    " 'OK',\n",
    " 'Another_number_3',\n",
    "'Pause',\n",
    " 'Shape_C',\n",
    " 'Make_a_phone_call',\n",
    "'Wave_hand',\n",
    " 'Wave_finger',\n",
    " 'Knock',\n",
    " 'Beckon',\n",
    " 'Palm_to_fist',\n",
    " 'Fist_to_Palm',\n",
    " 'Trigger_with_thumb',\n",
    " 'Trigger_with_index_finger',\n",
    " 'Hold_fist_in_the_other_hand',\n",
    " 'Grasp',\n",
    " 'Walk',\n",
    " 'Gather_fingers',\n",
    " 'Snap_fingers',\n",
    " 'Applaud',\n",
    " 'Dual_hands_heart',\n",
    " 'Put_two_fingers_together',\n",
    " 'Take_two_fingers_apart',\n",
    " 'Turn_over',\n",
    " 'Move_fist_upward',\n",
    " 'Move_fist_downward',\n",
    " 'Move_fist_toward_left',\n",
    " 'Move_fist_toward_right',\n",
    " 'Bring_hand_close',\n",
    " 'Push_away',\n",
    " 'Thumb_upward',\n",
    " 'Thumb_downward',\n",
    "'Thumb_toward_right',\n",
    " 'Thumb_toward_left',\n",
    " 'Thumbs_backward',\n",
    " 'Thumbs_forward',\n",
    " 'Move_hand_upward',\n",
    " 'Move_hand_downward',\n",
    " 'Move_hand_towards_left',\n",
    " 'Move_hand_towards_right',\n",
    " 'Draw_circle_with_hand_in_horizontal_surface',\n",
    "'Bent_number_2',\n",
    "'Bent_another_number_3',\n",
    "'Dual_fingers_heart',\n",
    "'Scroll_fingers_toward_left',\n",
    "'Scroll_fingers_toward_right',\n",
    "'Move_fingers_upward',\n",
    "'Move_fingers_downward',\n",
    "'81 Move_fingers_left',\n",
    "'Move_fingers_right',\n",
    "'Move_fingers_forward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize frames\n",
    "import matplotlib.image as img\n",
    "\n",
    "def resize_frame(frame, size = (64,64)):\n",
    "    frame = img.imread(frame)\n",
    "    frame = cv2.resize(frame, size)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return gray image\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=\"img\"):\n",
    "    cv2.imshow(title, img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def picker(sample_count):\n",
    "    L = []\n",
    "    for cl in sample_count:\n",
    "        L = L + [(f'{cl[1]}')]*cl[0]\n",
    "    random.shuffle(L)\n",
    "    return L\n",
    "\n",
    "def pick_sample(shuffled_list):\n",
    "    a = random.choice(shuffled_list)\n",
    "    return a\n",
    "\n",
    "def VideoDataGenerator(data_path, frame_dim, batch_size = 8):\n",
    "    '''The data_path must contain folders containing samples from only that class.\n",
    "    The samples should be homogenously numerated. (eg - 001.jpg, 002.jpg etc) for each frame of the video. \n",
    "    Enter frame_dim as tuple of dimensions in the format: (x-axis, y-axis)\n",
    "    Usage:\n",
    "        data_path: string format path to the directory containing your classes\n",
    "        frame_dim: a tuple of your width and height - (width, height) in pixels\n",
    "        batch_size: number of batches to be produced by the yield function, recommended 1,2,4,8 for regular computers\n",
    "    '''\n",
    "    def resize_frame(frame, size = frame_dim):\n",
    "        frame = img.imread(frame)\n",
    "        frame = cv2.resize(frame, size)\n",
    "        return frame\n",
    "    if data_path[-1] != '/':\n",
    "        data_path = f\"{data_path}/\"\n",
    "    \n",
    "    classes = os.listdir(data_path)\n",
    "    print(f\"{len(classes)} classes found in folder\")\n",
    "    \n",
    "    class_target_map = [[classes[i], i] for i in range(len(classes))]\n",
    "    samples_count = [[len(os.listdir(f\"{data_path}{classes[i]}\")), i] for i in range(len(classes))]\n",
    "    picker_list = picker(samples_count)\n",
    "    \n",
    "    sample_names = [[] for i in range(len(classes))]\n",
    "    for i in range(len(classes)):\n",
    "        sample_names[i] = os.listdir(f'{data_path}{classes[i]}')\n",
    "    \n",
    "    while True:\n",
    "        samples_pushed = []\n",
    "        offset = 0\n",
    "        total_samples = 0\n",
    "        c = 0\n",
    "        for cl in sample_names:\n",
    "            if not cl:\n",
    "                c += 1\n",
    "            if c == len(classes) - 1:\n",
    "                break\n",
    "        X = []\n",
    "        y = []\n",
    "        for cl in classes:\n",
    "            total_samples = total_samples + len(os.listdir(f'{data_path}{cl}'))\n",
    "            \n",
    "        for batch_iter in range(batch_size):\n",
    "            sample_class = pick_sample(picker_list)\n",
    "            picker_list.remove(sample_class)\n",
    "            sample_class = int(sample_class)\n",
    "            if not sample_names[sample_class]: \n",
    "                batch_iter -= 1\n",
    "                continue\n",
    "            vid_sample = f'{data_path}{classes[sample_class]}/{sample_names[sample_class][0]}'\n",
    "            #fuck up hoga toh ye^ line me hoga\n",
    "            frames = os.listdir(vid_sample)\n",
    "            frames.sort()\n",
    "            vid = []\n",
    "            for frame in frames:\n",
    "                frame = resize_frame(f'{vid_sample}/{frame}')\n",
    "                try:\n",
    "                    #frame = resize_frame(frame)\n",
    "                    vid.append(frame)\n",
    "                except:\n",
    "                    print(f'Sample with tag - {sample_names[sample_class][0]} is broken and skipped.')\n",
    "                    continue\n",
    "            #print(np.shape(vid))\n",
    "            #vid = np.reshape(vid, (96, 64, 32, 3))\n",
    "            X.append(vid)\n",
    "            y.append(sample_class)\n",
    "            \n",
    "            sample_names[sample_class].pop(0)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '/home/siddhant/Datasets/EgoGesture/EgoGesture2'\n",
    "validation_path = '/home/siddhant/Datasets/EgoGesture/test'\n",
    "\n",
    "batchsize = 2\n",
    "training_set = VideoDataGenerator(training_path, frame_dim=(96,64), batch_size=batchsize)\n",
    "validation_set = VideoDataGenerator(validation_path, frame_dim=(96,64), batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001)\n",
    "model.compile(optimizer=sgd, loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 classes found in folder\n"
     ]
    }
   ],
   "source": [
    "inst = next(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 64, 96, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(inst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = ModelCheckpoint(\n",
    "    os.getcwd(),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False, \n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('EGO.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8749/8750 [============================>.] - ETA: 0s - loss: 0.2494 - accuracy: 0.932083 classes found in folder\n",
      "INFO:tensorflow:Assets written to: /home/siddhant/Codes/3D EgoGesture/assets\n",
      "8750/8750 [==============================] - 3041s 348ms/step - loss: 0.2494 - accuracy: 0.9321 - val_loss: 0.0297 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit_generator(training_set, use_multiprocessing=True,\n",
    "                                       epochs =1,validation_data = validation_set , verbose = 1 , validation_steps = 1,\n",
    "                                       steps_per_epoch=140000//16, callbacks = [checkpoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(filepath='EGO.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('EGO.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Class =  Measure(distance) Precision =  11.85995489358902 %\n",
      ".Class =  Knock Precision =  11.954901367425919 %\n",
      ".Class =  Knock Precision =  12.476347386837006 %\n",
      ".Class =  Knock Precision =  8.666125684976578 %\n",
      ".Class =  Knock Precision =  8.861304074525833 %\n",
      ".Class =  Knock Precision =  8.924122154712677 %\n",
      ".Class =  Knock Precision =  9.842980653047562 %\n",
      ".Class =  Knock Precision =  8.927010744810104 %\n",
      ".Class =  Knock Precision =  9.655726701021194 %\n",
      ".Class =  Knock Precision =  9.927326440811157 %\n",
      ".Class =  Knock Precision =  10.277998447418213 %\n",
      ".Class =  Knock Precision =  9.683194011449814 %\n",
      ".Class =  Knock Precision =  10.13307198882103 %\n",
      ".Class =  Turn_over Precision =  57.19076991081238 %\n",
      ".Class =  Bent_another_number_3 Precision =  8.53370726108551 %\n",
      ".Class =  Bent_another_number_3 Precision =  8.971205353736877 %\n",
      ".Class =  Put_two_fingers_together Precision =  44.46413815021515 %\n",
      ".Class =  Bent_another_number_3 Precision =  21.286572515964508 %\n",
      ".Class =  Number_8 Precision =  6.102125719189644 %\n",
      ".Class =  Scroll_hand_forward Precision =  21.724432706832886 %\n",
      ".Class =  Move_fingers_upward Precision =  32.130420207977295 %\n",
      ".Class =  Number_8 Precision =  16.410572826862335 %\n",
      ".Class =  Trigger_with_index_finger Precision =  24.700407683849335 %\n",
      ".Class =  Number_8 Precision =  18.084950745105743 %\n",
      ".Class =  Number_8 Precision =  48.03140461444855 %\n",
      ".Class =  Put_two_fingers_together Precision =  14.072516560554504 %\n",
      ".Class =  Number_8 Precision =  16.714170575141907 %\n",
      ".Class =  Static_fist Precision =  24.277088046073914 %\n",
      ".Class =  Number_8 Precision =  20.55458277463913 %\n",
      ".Class =  Put_two_fingers_together Precision =  41.09296500682831 %\n",
      ".Class =  Number_8 Precision =  6.3190758228302 %\n",
      ".Class =  Thumb_upward Precision =  52.080947160720825 %\n",
      ".Class =  Turn_over Precision =  13.195282220840454 %\n",
      ".Class =  Knock Precision =  13.899905979633331 %\n",
      ".Class =  Number_8 Precision =  8.215709775686264 %\n",
      ".Class =  81 Move_fingers_left Precision =  10.042419284582138 %\n",
      ".Class =  Put_two_fingers_together Precision =  11.944416910409927 %\n",
      ".Class =  Number_8 Precision =  7.823753356933594 %\n",
      ".Class =  Zoom_in_with_fists Precision =  13.425891101360321 %\n",
      ".Class =  Number_8 Precision =  9.018979966640472 %\n",
      ".Class =  Number_8 Precision =  12.771867215633392 %\n",
      ".Class =  Zoom_in_with_fists Precision =  15.276075899600983 %\n",
      ".Class =  Static_fist Precision =  16.981634497642517 %\n",
      ".Class =  Number_8 Precision =  10.211417078971863 %\n",
      ".Class =  Move_hand_towards_left Precision =  23.88874888420105 %\n",
      ".Class =  Number_8 Precision =  14.085173606872559 %\n",
      ".Class =  Number_6 Precision =  12.424885481595993 %\n",
      ".Class =  Number_8 Precision =  9.53991413116455 %\n",
      ".Class =  Number_8 Precision =  12.371060252189636 %\n",
      ".Class =  Static_fist Precision =  16.210851073265076 %\n",
      ".Class =  Number_8 Precision =  12.267635017633438 %\n",
      ".Class =  Number_8 Precision =  9.71786230802536 %\n",
      ".Class =  Number_8 Precision =  11.659528315067291 %\n",
      ".Class =  Rotate_fingers_clockwise Precision =  18.801386654376984 %\n",
      ".Class =  Static_fist Precision =  16.268546879291534 %\n",
      ".Class =  Rotate_fingers_clockwise Precision =  16.789665818214417 %\n",
      ".Class =  Move_fingers_upward Precision =  12.11344301700592 %\n",
      ".Class =  Knock Precision =  15.987125039100647 %\n",
      ".Class =  Bent_another_number_3 Precision =  19.20369565486908 %\n",
      ".Class =  Rotate_fingers_clockwise Precision =  10.79065278172493 %\n",
      ".Class =  Number_6 Precision =  35.84706783294678 %\n",
      ".Class =  Thumbs_forward Precision =  24.490581452846527 %\n",
      ".Class =  Thumbs_forward Precision =  72.1244215965271 %\n"
     ]
    }
   ],
   "source": [
    "to_predict = []\n",
    "num_frames = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(12, 50)\n",
    "cap.set(6, 10)\n",
    "classe = ''\n",
    "import time \n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_cp = frame\n",
    "    #print(cap.get(6))\n",
    "    frame_cp = cv2.resize(frame, (96, 64))\n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    to_predict.append(frame_cp)\n",
    "    \n",
    "    if len(to_predict) == 16:\n",
    "        print(\".\", end=\"\")\n",
    "        frame_to_predict = [[]]\n",
    "        frame_to_predict[0] = np.array(to_predict, dtype=np.float32)\n",
    "        #frame_to_predict = normaliz_data(frame_to_predict)\n",
    "        #print(frame_to_predict)\n",
    "        predict = model.predict(np.array(frame_to_predict))\n",
    "        time.sleep(0.1)\n",
    "        classe = classes[np.argmax(predict)]\n",
    "        if np.argmax(predict)!=2:\n",
    "            print('Class = ',classe, 'Precision = ', np.amax(predict)*100,'%')\n",
    "\n",
    "\n",
    "        #print(frame_to_predict)\n",
    "        to_predict = []\n",
    "        time.sleep(0.1) # Time in seconds\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, classe, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0.5, 0.5),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Hand Gesture Recognition',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 classes found in folder\n",
      "Test loss: 0.32248181104660034\n",
      "Test accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "testing_set = VideoDataGenerator(validation_path, frame_dim=(96,64), batch_size=16)\n",
    "inst = next(testing_set)\n",
    "\n",
    "score = model.evaluate(inst[0], inst[1], verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
